{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Food Classification Using Deep Neural Networks and Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Splitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training, validation, and test sets. Justify your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import shutil\n",
    "import os\n",
    "import random\n",
    "random.seed = 2019\n",
    "split = [600,200,200]\n",
    "\n",
    "for food in ['falafel','apple_pie','donuts','french_fries','macarons','nachos','onion_rings','oysters','pizza', 'mussels']:\n",
    "    \n",
    "    #create new empty folders\n",
    "    if not os.path.exists('train/' + food):\n",
    "        os.makedirs('train/' + food)\n",
    "    if not os.path.exists('val/' + food):\n",
    "        os.makedirs('val/' + food)\n",
    "    if not os.path.exists('test/' + food):\n",
    "        os.makedirs('test/' + food)\n",
    "    \n",
    "    #make a list of image file names, shuffle them\n",
    "    pictures = os.listdir(\"Food Chosen/\"+ food)\n",
    "    pictures.sort()\n",
    "    random.shuffle(pictures)\n",
    "    \n",
    "    #copy images into folders\n",
    "    for pic in pictures[0:split[0]]:\n",
    "        shutil.copy(\"Food Chosen/\"+ food +\"/\"+ pic,\"train/\"+food+\"/\"+pic)\n",
    "        print(\"copy\",\"Food Chosen/\"+ food +\"/\"+ pic,\"to\",\"train/\"+food+\"/\"+pic)\n",
    "        \n",
    "    for pic in pictures[split[0]:split[0]+split[1]]:\n",
    "        shutil.copy(\"Food Chosen/\"+ food +\"/\"+ pic,\"val/\"+food+\"/\"+pic)\n",
    "        print(\"copy\",\"Food Chosen/\"+ food +\"/\"+ pic,\"to\",\"val/\"+food+\"/\"+pic)\n",
    "        \n",
    "    for pic in pictures[split[1]:sum(split)]:\n",
    "        shutil.copy(\"Food Chosen/\"+ food +\"/\"+ pic,\"test/\"+food+\"/\"+pic)\n",
    "        print(\"copy\",\"Food Chosen/\"+ food +\"/\"+ pic,\"to\",\"test/\"+food+\"/\"+pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(target_classes, batch_size):\n",
    "    \"\"\" Returns the indices for datapoints in the dataset that\n",
    "    belongs to the desired target classes, a subset of all possible classes.\n",
    "\n",
    "    Args:\n",
    "        dataset: Dataset object\n",
    "        classes: A list of strings denoting the name of each class\n",
    "        target_classes: A list of strings denoting the name of the desired\n",
    "                        classes. Should be a subset of the argument 'classes'\n",
    "    Returns:\n",
    "        indices: list of indices that have labels corresponding to one of the\n",
    "                 target classes\n",
    "    \"\"\"\n",
    "    classes = ('falafel','apple_pie','donuts','french_fries','macarons','nachos','onion_rings','oysters','pizza', 'mussels')\n",
    "\n",
    "    ########################################################################\n",
    "    # The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "    # We transform them to Tensors of normalized range [-1, 1].\n",
    "    transform = transforms.Compose(\n",
    "    [transforms.Resize((224,224), interpolation=2), transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.ImageFolder(root = 'train',\n",
    "                                                 transform=transform)\n",
    " \n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size = batch_size,\n",
    "                                              num_workers = 1, shuffle = True)\n",
    "\n",
    "    \n",
    "    val_set = torchvision.datasets.ImageFolder(root='val',\n",
    "                                                 transform=transform)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,\n",
    "                                              num_workers=1, shuffle = True)\n",
    "\n",
    "    testset = torchvision.datasets.ImageFolder(root= 'test',\n",
    "                                            transform=transform)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                             num_workers=1, shuffle = True)\n",
    "\n",
    "    return train_loader, classes#, val_loader, test_loader, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('falafel','apple_pie','donuts','french_fries','macarons','nachos','onion_rings','oysters','pizza', 'mussels')\n",
    "\n",
    "########################################################################\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1].\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((224,224), interpolation=2), transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root = 'train',\n",
    "                                             transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size = 64,\n",
    "                                          num_workers = 1, shuffle = True)\n",
    "val_set = torchvision.datasets.ImageFolder(root='val',\n",
    "                                                 transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=64,\n",
    "                                              num_workers=1, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root= 'test',\n",
    "                                            transform=transform)\n",
    "    \n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                             num_workers=1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple_pie': 0,\n",
       " 'donuts': 1,\n",
       " 'falafel': 2,\n",
       " 'french_fries': 3,\n",
       " 'macarons': 4,\n",
       " 'mussels': 5,\n",
       " 'nachos': 6,\n",
       " 'onion_rings': 7,\n",
       " 'oysters': 8,\n",
       " 'pizza': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.class_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "tensor([4, 3, 8, 5, 5, 3, 9, 5, 7, 5, 2, 6, 2, 2, 3, 0, 1, 4, 4, 9, 2, 8, 7, 2,\n",
      "        4, 4, 0, 4, 9, 8, 5, 1, 2, 8, 8, 6, 9, 6, 8, 6, 9, 4, 6, 1, 0, 5, 7, 6,\n",
      "        8, 7, 8, 2, 3, 1, 4, 4, 2, 5, 0, 9, 6, 7, 0, 4])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_loader_iter = iter(train_loader)\n",
    "imgs, labels = next(train_loader_iter)\n",
    "print(imgs.shape)\n",
    "print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convolutional Network - Baseline Model \n",
    "Build a convolutional neural network model that takes the (224x224 RGB) image as input, and predicts the letter. Your model should be a subclass of nn.Module. Explain your choice of neural network architecture: how many layers did you choose? What types of layers did you use? Were they fully-connected or convolutional? What about other decisions like pooling layers, activation functions, number of channels / hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    " \n",
    "class LargeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LargeNet, self).__init__()\n",
    "        self.name = \"large\"\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding = 1) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 28 * 28)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) \n",
    "        x = x.squeeze(1) # Flatten to [batch_size]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training \n",
    "Train your network. Plot the training curve.\n",
    "\n",
    "Make sure that you are checkpointing frequently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# convolutional neural network, \n",
    "class LargeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LargeNet, self).__init__()\n",
    "        self.name = \"large\"\n",
    "        self.conv1 = nn.Conv2d(3, 5, 3, padding = 1) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 10, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(10, 15, 3, padding = 1)\n",
    "        self.fc1 = nn.Linear(15 * 28 * 28 , 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        x = x.view(-1, 15 * 28 * 28)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) \n",
    "        x = x.squeeze(1) # Flatten to [batch_size]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(name, batch_size, learning_rate, epoch):\n",
    "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
    "\n",
    "    Args:\n",
    "        config: Configuration object containing the hyperparameters\n",
    "    Returns:\n",
    "        path: A string with the hyperparameter name and value concatenated\n",
    "    \"\"\"\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "tensor([5, 9, 4, 4, 6, 0, 8, 3, 5, 4, 9, 4, 4, 9, 8, 7, 9, 6, 9, 6, 9, 3, 7, 4,\n",
      "        2, 7, 9, 6, 4, 8, 0, 1, 5, 0, 8, 3, 5, 7, 8, 2, 2, 4, 4, 8, 0, 2, 8, 6,\n",
      "        9, 9, 9, 5, 2, 4, 2, 9, 6, 8, 1, 3, 1, 9, 6, 2])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_loader_iter = iter(train_loader)\n",
    "imgs, labels = next(train_loader_iter)\n",
    "print(imgs.shape)\n",
    "print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, loader, criterion):\n",
    "    \"\"\" Evaluate the network on the validation set.\n",
    "\n",
    "     Args:\n",
    "         net: PyTorch neural network object\n",
    "         loader: PyTorch data loader for the validation set\n",
    "         criterion: The loss function\n",
    "     Returns:\n",
    "         err: A scalar for the avg classification error over the validation set\n",
    "         loss: A scalar for the average loss function over the validation set\n",
    "     \"\"\"\n",
    "    total_loss = 0.0\n",
    "    total_err = 0.0\n",
    "    total_epoch = 0\n",
    "\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        pred = outputs.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        total_err += pred.ne(labels.view_as(pred)).sum().item()\n",
    "        total_loss += loss.item()\n",
    "        total_epoch += len(labels)\n",
    "\n",
    "    err = float(total_err) / total_epoch\n",
    "    loss = float(total_loss) / (i + 1)\n",
    "\n",
    "    return err, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, batch_size=1, learning_rate=0.0001, num_epochs=30):\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.Resize((224,224)), transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    trainset = torchvision.datasets.ImageFolder(root='train',\n",
    "                                                 transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          num_workers=1, shuffle = True)\n",
    "    \n",
    "    train_loader_iter = iter(train_loader)\n",
    "    imgs, labels = next(train_loader_iter)\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(1000)\n",
    "\n",
    "   \n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    train_err = np.zeros(num_epochs)\n",
    "    train_loss = np.zeros(num_epochs)\n",
    "    val_err = np.zeros(num_epochs)\n",
    "    val_loss = np.zeros(num_epochs)\n",
    "    \n",
    "    \n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "    start_time = time.time()\n",
    "    # training\n",
    "    n=0\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times \n",
    "      \n",
    "        total_train_loss = 0.0\n",
    "        total_train_err = 0.0\n",
    "\n",
    "        total_epoch = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            inputs, labels = data\n",
    "                      \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "           \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iters.append(n)\n",
    "           \n",
    "            pred = outputs.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            total_train_err += pred.ne(labels.view_as(pred)).sum().item()\n",
    "            total_train_loss += loss.item()\n",
    "            total_epoch += len(labels)\n",
    "           \n",
    "            losses.append(float(loss)/batch_size)  \n",
    "            n += 1# compute *average* loss\n",
    "        \n",
    "        train_err[epoch] = float(total_train_err) / total_epoch\n",
    "     \n",
    "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
    "        \n",
    "        val_err[epoch], val_loss[epoch] = evaluate(net, val_loader, criterion)\n",
    "    \n",
    "        print((\"Epoch {}: Train err: {}, Train loss: {}  |\" +\n",
    "               \"Validation err: {} , Validation loss:{} \").format(\n",
    "                   epoch + 1,\n",
    "            \n",
    "                   train_err[epoch],\n",
    "                   train_loss[epoch],\n",
    "                   val_err[epoch],\n",
    "                   val_loss[epoch]\n",
    "                        ))\n",
    "\n",
    "        # Save the current model (checkpoint) to a file\n",
    "        model_path = get_model_name(net.name, batch_size, learning_rate, epoch)\n",
    "        torch.save(net.state_dict(), model_path)\n",
    "\n",
    "    print('Finished Training')\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
    "\n",
    "    # Write the train/test loss/err into CSV file for plotting later\n",
    "    epochs = np.arange(1, num_epochs + 1)\n",
    "\n",
    "    np.savetxt(\"{}_train_err.csv\".format(model_path), train_err)\n",
    "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
    "    np.savetxt(\"{}_val_err.csv\".format(model_path), val_err)\n",
    "    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)\n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Curve\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_training_curve(path):\n",
    "    \"\"\" Plots the training curve for a model run, given the csv files\n",
    "    containing the train/validation error/loss.\n",
    "\n",
    "    Args:\n",
    "        path: The base path of the csv files produced during training\n",
    "    \"\"\"\n",
    "\n",
    "    train_err = np.loadtxt(\"{}_train_err.csv\".format(path))\n",
    "    val_err = np.loadtxt(\"{}_val_err.csv\".format(path))\n",
    "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
    "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
    "    plt.title(\"Train vs Validation Error\")\n",
    "    plt.plot(range(1,16), train_err, label=\"Train\")\n",
    "    plt.plot(range(1,16), val_err, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    plt.title(\"Train vs Validation Loss\")\n",
    "    plt.plot(range(1,16), train_loss, label=\"Train\")\n",
    "    plt.plot(range(1,16), val_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Seach - Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne3 = LargeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train err: 0.8148333333333333, Train loss: 2.158148763027597  |Validation err: 0.723 , Validation loss:2.009124256670475 \n",
      "Epoch 2: Train err: 0.7078333333333333, Train loss: 1.9445663310111838  |Validation err: 0.7025 , Validation loss:1.9168030060827732 \n",
      "Epoch 3: Train err: 0.6698333333333333, Train loss: 1.856111766176021  |Validation err: 0.6735 , Validation loss:1.9394507482647896 \n",
      "Epoch 4: Train err: 0.628, Train loss: 1.7505208304587832  |Validation err: 0.641 , Validation loss:1.867951549589634 \n",
      "Epoch 5: Train err: 0.5693333333333334, Train loss: 1.6187293821192803  |Validation err: 0.658 , Validation loss:1.9066818878054619 \n",
      "Epoch 6: Train err: 0.5073333333333333, Train loss: 1.456289514582208  |Validation err: 0.642 , Validation loss:1.8620629645884037 \n",
      "Epoch 7: Train err: 0.41933333333333334, Train loss: 1.2551947939903179  |Validation err: 0.659 , Validation loss:2.0057723075151443 \n",
      "Epoch 8: Train err: 0.351, Train loss: 1.0611330454653882  |Validation err: 0.6685 , Validation loss:2.1008864864706993 \n",
      "Epoch 9: Train err: 0.2831666666666667, Train loss: 0.8560824400566994  |Validation err: 0.674 , Validation loss:2.3106570430099964 \n",
      "Epoch 10: Train err: 0.21933333333333332, Train loss: 0.670113834611913  |Validation err: 0.6725 , Validation loss:2.7050860971212387 \n",
      "Epoch 11: Train err: 0.15133333333333332, Train loss: 0.4867108572036662  |Validation err: 0.684 , Validation loss:3.072967253625393 \n",
      "Epoch 12: Train err: 0.1045, Train loss: 0.3489989275310902  |Validation err: 0.704 , Validation loss:3.4543755501508713 \n",
      "Epoch 13: Train err: 0.06333333333333334, Train loss: 0.24077464069457763  |Validation err: 0.695 , Validation loss:4.020204208791256 \n",
      "Epoch 14: Train err: 0.037333333333333336, Train loss: 0.1562779146306058  |Validation err: 0.694 , Validation loss:4.432932212948799 \n",
      "Epoch 15: Train err: 0.024, Train loss: 0.1047970599475059  |Validation err: 0.6975 , Validation loss:4.853061161935329 \n",
      "Finished Training\n",
      "Total time elapsed: 4125.04 seconds\n"
     ]
    }
   ],
   "source": [
    "train(ne3, batch_size = 64, learning_rate=0.001, num_epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train err: 0.905, Train loss: 69.27644053164948  |Validation err: 0.9 , Validation loss:2.305116042494774 \n",
      "Epoch 2: Train err: 0.8991666666666667, Train loss: 2.310235708317858  |Validation err: 0.9 , Validation loss:2.306180879473686 \n",
      "Epoch 3: Train err: 0.9078333333333334, Train loss: 2.3106132263832904  |Validation err: 0.9 , Validation loss:2.3110063523054123 \n",
      "Epoch 4: Train err: 0.9058333333333334, Train loss: 2.3119596395086734  |Validation err: 0.9 , Validation loss:2.3066415563225746 \n",
      "Epoch 5: Train err: 0.8973333333333333, Train loss: 2.312528721829678  |Validation err: 0.9 , Validation loss:2.3107978478074074 \n",
      "Epoch 6: Train err: 0.9033333333333333, Train loss: 2.3107845377414784  |Validation err: 0.9 , Validation loss:2.317298397421837 \n",
      "Epoch 7: Train err: 0.9025, Train loss: 2.3116819300550095  |Validation err: 0.9 , Validation loss:2.311502568423748 \n",
      "Epoch 8: Train err: 0.9026666666666666, Train loss: 2.313047170639038  |Validation err: 0.9 , Validation loss:2.3057210743427277 \n",
      "Epoch 9: Train err: 0.904, Train loss: 2.309322917715032  |Validation err: 0.9 , Validation loss:2.3094464614987373 \n",
      "Epoch 10: Train err: 0.9031666666666667, Train loss: 2.3102539295845843  |Validation err: 0.9 , Validation loss:2.3178758919239044 \n",
      "Epoch 11: Train err: 0.9001666666666667, Train loss: 2.310974729822037  |Validation err: 0.9 , Validation loss:2.309593439102173 \n",
      "Epoch 12: Train err: 0.9051666666666667, Train loss: 2.311133493768408  |Validation err: 0.9 , Validation loss:2.3068631663918495 \n",
      "Epoch 13: Train err: 0.9061666666666667, Train loss: 2.3110781071033886  |Validation err: 0.9 , Validation loss:2.3089632838964462 \n",
      "Epoch 14: Train err: 0.8958333333333334, Train loss: 2.3131964434968664  |Validation err: 0.9 , Validation loss:2.307108908891678 \n",
      "Epoch 15: Train err: 0.904, Train loss: 2.3099847017450537  |Validation err: 0.9 , Validation loss:2.312180735170841 \n",
      "Finished Training\n",
      "Total time elapsed: 3797.03 seconds\n"
     ]
    }
   ],
   "source": [
    "ne3 = LargeNet()\n",
    "train(ne3, batch_size = 64, learning_rate=0.1, num_epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train err: 0.9795918367346939, Train loss: 2.3734283447265625  |Validation err: 0.888 , Validation loss:2.3043167099120123 \n",
      "Epoch 2: Train err: 0.9081632653061225, Train loss: 2.290855824947357  |Validation err: 0.8775 , Validation loss:2.302852191622295 \n",
      "Epoch 3: Train err: 0.8061224489795918, Train loss: 2.2846043705940247  |Validation err: 0.901 , Validation loss:2.314066497106401 \n",
      "Epoch 4: Train err: 0.8367346938775511, Train loss: 2.13023641705513  |Validation err: 0.907 , Validation loss:2.341324866764129 \n",
      "Epoch 5: Train err: 0.7142857142857143, Train loss: 2.084831118583679  |Validation err: 0.8955 , Validation loss:2.4171635347699363 \n",
      "Epoch 6: Train err: 0.6938775510204082, Train loss: 1.9880781471729279  |Validation err: 0.883 , Validation loss:2.561256310296437 \n",
      "Epoch 7: Train err: 0.6836734693877551, Train loss: 1.9308159351348877  |Validation err: 0.9 , Validation loss:2.717611956217932 \n",
      "Epoch 8: Train err: 0.5918367346938775, Train loss: 1.7282463312149048  |Validation err: 0.89 , Validation loss:2.5405312568422347 \n",
      "Epoch 9: Train err: 0.41836734693877553, Train loss: 1.5219750106334686  |Validation err: 0.8765 , Validation loss:2.627961692355928 \n",
      "Epoch 10: Train err: 0.35714285714285715, Train loss: 1.273184359073639  |Validation err: 0.8715 , Validation loss:3.0133936064583913 \n",
      "Epoch 11: Train err: 0.2653061224489796, Train loss: 1.287275642156601  |Validation err: 0.8675 , Validation loss:3.3288279979948014 \n",
      "Epoch 12: Train err: 0.23469387755102042, Train loss: 0.7658655345439911  |Validation err: 0.866 , Validation loss:3.502179774027022 \n",
      "Epoch 13: Train err: 0.1836734693877551, Train loss: 0.6691552400588989  |Validation err: 0.8655 , Validation loss:3.90644105275472 \n",
      "Epoch 14: Train err: 0.20408163265306123, Train loss: 0.6687202155590057  |Validation err: 0.879 , Validation loss:5.183150215754433 \n",
      "Epoch 15: Train err: 0.14285714285714285, Train loss: 0.4501984044909477  |Validation err: 0.8645 , Validation loss:5.283411022216555 \n",
      "Finished Training\n",
      "Total time elapsed: 836.36 seconds\n"
     ]
    }
   ],
   "source": [
    "ne3 = LargeNet()\n",
    "train(ne3, batch_size = 32, learning_rate=0.001, num_epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train err: 0.9693877551020408, Train loss: 3.077807307243347  |Validation err: 0.8865 , Validation loss:2.302529043621487 \n",
      "Epoch 2: Train err: 0.8673469387755102, Train loss: 2.314727246761322  |Validation err: 0.885 , Validation loss:2.3035942410665844 \n",
      "Epoch 3: Train err: 0.9081632653061225, Train loss: 2.3299266695976257  |Validation err: 0.872 , Validation loss:2.303005570457095 \n",
      "Epoch 4: Train err: 0.8367346938775511, Train loss: 2.2420854568481445  |Validation err: 0.8975 , Validation loss:2.307703521516588 \n",
      "Epoch 5: Train err: 0.8163265306122449, Train loss: 2.2963311076164246  |Validation err: 0.9065 , Validation loss:2.3334713776906333 \n",
      "Epoch 6: Train err: 0.7244897959183674, Train loss: 2.034865379333496  |Validation err: 0.8985 , Validation loss:2.681612801930261 \n",
      "Epoch 7: Train err: 0.6326530612244898, Train loss: 1.9049053490161896  |Validation err: 0.8875 , Validation loss:2.4091070341685463 \n",
      "Epoch 8: Train err: 0.4387755102040816, Train loss: 1.718448281288147  |Validation err: 0.8875 , Validation loss:4.1575292746226 \n",
      "Epoch 9: Train err: 0.3673469387755102, Train loss: 1.3270516842603683  |Validation err: 0.8785 , Validation loss:2.9600095446147616 \n",
      "Epoch 10: Train err: 0.14285714285714285, Train loss: 0.6192267537117004  |Validation err: 0.8745 , Validation loss:3.4025273663657054 \n",
      "Epoch 11: Train err: 0.04081632653061224, Train loss: 0.4081924967467785  |Validation err: 0.8905 , Validation loss:5.167965783013238 \n",
      "Epoch 12: Train err: 0.0, Train loss: 0.06718670018017292  |Validation err: 0.8905 , Validation loss:7.451772182706803 \n",
      "Epoch 13: Train err: 0.0, Train loss: 0.013560919091105461  |Validation err: 0.8815 , Validation loss:9.02139563787551 \n",
      "Epoch 14: Train err: 0.0, Train loss: 0.004027426242828369  |Validation err: 0.88 , Validation loss:11.538469473520914 \n",
      "Epoch 15: Train err: 0.0, Train loss: 0.004958149045705795  |Validation err: 0.8855 , Validation loss:12.139621984390985 \n",
      "Finished Training\n",
      "Total time elapsed: 908.44 seconds\n"
     ]
    }
   ],
   "source": [
    "ne3 = LargeNet()\n",
    "train(ne3, batch_size = 32, learning_rate=0.01, num_epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train err: 0.9693877551020408, Train loss: 550.2931333184242  |Validation err: 0.905 , Validation loss:2.7689754281725203 \n",
      "Epoch 2: Train err: 0.9387755102040817, Train loss: 3.7385972142219543  |Validation err: 0.8995 , Validation loss:2.7221766918424577 \n",
      "Epoch 3: Train err: 0.9489795918367347, Train loss: 2.364147186279297  |Validation err: 0.9005 , Validation loss:2.3685239383152554 \n",
      "Epoch 4: Train err: 0.8979591836734694, Train loss: 2.294677972793579  |Validation err: 0.901 , Validation loss:2.4256414572397866 \n",
      "Epoch 5: Train err: 0.8979591836734694, Train loss: 2.3738736510276794  |Validation err: 0.9 , Validation loss:2.4190590078868563 \n",
      "Epoch 6: Train err: 0.8979591836734694, Train loss: 2.3401819467544556  |Validation err: 0.8995 , Validation loss:2.438799407747057 \n",
      "Epoch 7: Train err: 0.8979591836734694, Train loss: 2.3592366576194763  |Validation err: 0.8985 , Validation loss:2.38091674683586 \n",
      "Epoch 8: Train err: 0.8775510204081632, Train loss: 2.2866302728652954  |Validation err: 0.8965 , Validation loss:2.601626403748043 \n",
      "Epoch 9: Train err: 0.8061224489795918, Train loss: 2.2444815039634705  |Validation err: 0.8935 , Validation loss:2.5651551428295316 \n",
      "Epoch 10: Train err: 0.8571428571428571, Train loss: 2.1443129777908325  |Validation err: 0.8925 , Validation loss:3.048185113876585 \n",
      "Epoch 11: Train err: 0.8571428571428571, Train loss: 2.103884845972061  |Validation err: 0.889 , Validation loss:4.784944784073603 \n",
      "Epoch 12: Train err: 0.826530612244898, Train loss: 2.1493271589279175  |Validation err: 0.89 , Validation loss:4.122432595207577 \n",
      "Epoch 13: Train err: 0.7755102040816326, Train loss: 2.1442636251449585  |Validation err: 0.888 , Validation loss:3.6297548195672413 \n",
      "Epoch 14: Train err: 0.7857142857142857, Train loss: 1.9419246017932892  |Validation err: 0.9025 , Validation loss:9.967673778533936 \n",
      "Epoch 15: Train err: 0.826530612244898, Train loss: 4.167471766471863  |Validation err: 0.896 , Validation loss:2.463040344298832 \n",
      "Finished Training\n",
      "Total time elapsed: 674.44 seconds\n"
     ]
    }
   ],
   "source": [
    "ne3 = LargeNet()\n",
    "train(ne3, batch_size = 32, learning_rate=0.1, num_epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'model_large_bs64_lr0.001_epoch14'\n",
    "plot_training_curve(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Classification Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LargeNet()\n",
    "model_path = get_model_name(net.name, batch_size=64, learning_rate=0.001, epoch=5)\n",
    "state = torch.load(model_path)\n",
    "net.load_state_dict(state)\n",
    "\n",
    "evaluate(net, test_loader, nn.CrossEntropyLoss())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The test classification error was about 0.37."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model):\n",
    "    data = testset\n",
    "    total = 0\n",
    "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=32):\n",
    "        output = model(imgs) # We don't need to run F.softmax\n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LargeNet()\n",
    "model_path = get_model_name(net.name, batch_size=64, learning_rate=0.001, epoch=5)\n",
    "state = torch.load(model_path)\n",
    "net.load_state_dict(state)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6222222222222222"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(net)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test accuracy was about 62 %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Transfer Learning [16 pt]\n",
    "For many image classification tasks, it is generally not a good idea to train a very large Deep Neural Network model from scratch due to the enormous compute requirements and lack of sufficient amounts of training data. One of the better option is to try using an existing model that performs a similar task to the one you need to solve. This method of utilizing a pre-trained network for other similar tasks is broadly termed Transfer Learning. In this assignment, we will use Transfer Learning to extract features from the hand gesture images. Then, train a smaller network to use these features as input and classify the hand gestures.\n",
    "\n",
    "As you have learned from the CNN lecture, Convolution layers extract various features from the images which get utilized by the fully connected layers for correct classification. AlexNet architecture played a pivotal role in establishing Deep Neural Nets as a go-to tool for Image classification problems and we will use an imagenet pre-trained AlexNet model to extract features in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.nn import functional as F\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Feature Extraction using AlexNet pretrained model\n",
    "\n",
    "class AlexNetFeatures(nn.Module):\n",
    "    '''\n",
    "    Class that loads AlexNet Feature Model ('Convolution layers') with imagenet trained weights\n",
    "    \n",
    "    input : image tensors with dimension Lx3x224x224\n",
    "    \n",
    "    output : feature tensor with dimension Lx256x6x6\n",
    "    \n",
    "    *L - Batch size\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def load_weights(self):\n",
    "        an_builtin = torchvision.models.alexnet(pretrained=True) # Loads the pretrained model weights\n",
    "        \n",
    "        features_weight_i = [0, 3, 6, 8, 10]\n",
    "        for i in features_weight_i:\n",
    "            self.features[i].weight = an_builtin.features[i].weight\n",
    "            self.features[i].bias = an_builtin.features[i].bias\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNetFeatures, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.load_weights() # Copies the weights to AlexNetFeatures model layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfeature_model = AlexNetFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ccc027377017>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyfeature_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "    inputs, labels = data\n",
    " \n",
    "    features = myfeature_model(inputs)\n",
    "for i, data in enumerate(val_loader, 0):\n",
    "\n",
    "    inputs, labels = data\n",
    " \n",
    "    features = myfeature_model(inputs)\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "\n",
    "    inputs, labels = data\n",
    " \n",
    "    features = myfeature_model(inputs)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (b) [5 pt]\n",
    "Build a convolutional neural network model that takes as input these AlexNet features, and makes a prediction. Your model should be a subclass of nn.Module.\n",
    "\n",
    "Explain your choice of neural network architecture: how many layers did you choose? What types of layers did you use: fully-connected or convolutional? What about other decisions like pooling layers, activation functions, number of channels / hidden units in each layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network For AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.name = \"transferNet\"\n",
    "        self.conv1 = nn.Conv2d(256, 1, 3) \n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, 9)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = x.squeeze(1) # Flatten to [batch_size]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training With AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate2(net, loader, criterion):\n",
    "    \"\"\" Evaluate the network on the validation set.\n",
    "\n",
    "     Args:\n",
    "         net: PyTorch neural network object\n",
    "         loader: PyTorch data loader for the validation set\n",
    "         criterion: The loss function\n",
    "     Returns:\n",
    "         err: A scalar for the avg classification error over the validation set\n",
    "         loss: A scalar for the average loss function over the validation set\n",
    "     \"\"\"\n",
    "    total_loss = 0.0\n",
    "    total_err = 0.0\n",
    "    total_epoch = 0\n",
    "\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        features = myfeature_model(inputs)\n",
    "        outputs = net(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        pred = outputs.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        total_err += pred.ne(labels.view_as(pred)).sum().item()\n",
    "        total_loss += loss.item()\n",
    "        total_epoch += len(labels)\n",
    "\n",
    "    err = float(total_err) / total_epoch\n",
    "    loss = float(total_loss) / (i + 1)\n",
    "\n",
    "    return err, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainm(net, batch_size=64, learning_rate=0.0001, num_epochs=30):\n",
    "  \n",
    "    target_classes = [\"A\", \"B\", \"C\", \"D\",\n",
    "               \"E\", \"F\", \"G\", \"H\", \"I\"]\n",
    "    \n",
    "    torch.manual_seed(1000)\n",
    "\n",
    "    train_loader, val_loader, test_loader, classes = get_data_loader(\n",
    "            target_classes, batch_size)\n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    train_err = np.zeros(num_epochs)\n",
    "    train_loss = np.zeros(num_epochs)\n",
    "    val_err = np.zeros(num_epochs)\n",
    "    val_loss = np.zeros(num_epochs)\n",
    "    \n",
    "    \n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "    start_time = time.time()\n",
    "    # training\n",
    "    n=0\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times \n",
    "        total_train_loss = 0.0\n",
    "        total_train_err = 0.0\n",
    "\n",
    "        total_epoch = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            features = myfeature_model(inputs)\n",
    "            outputs = net(features)\n",
    "            prob = F.softmax(outputs, dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iters.append(n)\n",
    "           \n",
    "            pred = outputs.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            total_train_err += pred.ne(labels.view_as(pred)).sum().item()\n",
    "            total_train_loss += loss.item()\n",
    "            total_epoch += len(labels)\n",
    "           \n",
    "            losses.append(float(loss)/batch_size)  \n",
    "            n += 1# compute *average* loss\n",
    "        \n",
    "        train_err[epoch] = float(total_train_err) / total_epoch\n",
    "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
    "        val_err[epoch], val_loss[epoch] = evaluate2(net, val_loader, criterion)\n",
    "        \n",
    "        print((\"Epoch {}: Train err: {}, Train loss: {} |\"+\n",
    "               \"Validation err: {}, Validation loss: {}\").format(\n",
    "                   epoch + 1,\n",
    "                   train_err[epoch],\n",
    "                   train_loss[epoch],\n",
    "                   val_err[epoch],\n",
    "                   val_loss[epoch]))\n",
    "\n",
    "        # Save the current model (checkpoint) to a file\n",
    "        model_path = get_model_name(net.name, batch_size, learning_rate, epoch)\n",
    "        torch.save(net.state_dict(), model_path)\n",
    "\n",
    "    print('Finished Training')\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
    "\n",
    "    # Write the train/test loss/err into CSV file for plotting later\n",
    "    epochs = np.arange(1, num_epochs + 1)\n",
    "\n",
    "    np.savetxt(\"{}_train_err.csv\".format(model_path), train_err)\n",
    "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
    "    np.savetxt(\"{}_val_err.csv\".format(model_path), val_err)\n",
    "    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)\n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search With AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train err: 0.8595113438045375, Train loss: 2.191327426550068 |Validation err: 0.7489711934156379, Validation loss: 2.1361649968496565\n",
      "Epoch 2: Train err: 0.7556719022687609, Train loss: 2.1192364577223493 |Validation err: 0.7325102880658436, Validation loss: 2.061200148774763\n",
      "Epoch 3: Train err: 0.7260034904013961, Train loss: 2.0557315695972345 |Validation err: 0.6995884773662552, Validation loss: 2.004276502770161\n",
      "Epoch 4: Train err: 0.6858638743455497, Train loss: 1.9838839731915459 |Validation err: 0.6255144032921811, Validation loss: 1.9033872144212447\n",
      "Epoch 5: Train err: 0.6431064572425829, Train loss: 1.9034680759511484 |Validation err: 0.5679012345679012, Validation loss: 1.8201030124852686\n",
      "Epoch 6: Train err: 0.6212914485165794, Train loss: 1.833899358388225 |Validation err: 0.5390946502057613, Validation loss: 1.734129064858205\n",
      "Epoch 7: Train err: 0.5916230366492147, Train loss: 1.745175765967078 |Validation err: 0.5390946502057613, Validation loss: 1.5938884333818537\n",
      "Epoch 8: Train err: 0.5706806282722513, Train loss: 1.6464415397527539 |Validation err: 0.5267489711934157, Validation loss: 1.5038281139522913\n",
      "Epoch 9: Train err: 0.5488656195462478, Train loss: 1.5831324979272812 |Validation err: 0.49794238683127573, Validation loss: 1.4408074259267423\n",
      "Epoch 10: Train err: 0.5427574171029669, Train loss: 1.5330508511519974 |Validation err: 0.48559670781893005, Validation loss: 1.38964483620208\n",
      "Epoch 11: Train err: 0.5200698080279232, Train loss: 1.4925794872938025 |Validation err: 0.48559670781893005, Validation loss: 1.3416618084220728\n",
      "Epoch 12: Train err: 0.5113438045375218, Train loss: 1.4582794526068537 |Validation err: 0.4567901234567901, Validation loss: 1.30807442282453\n",
      "Epoch 13: Train err: 0.5087260034904014, Train loss: 1.4280258369279366 |Validation err: 0.4691358024691358, Validation loss: 1.2797835506038902\n",
      "Epoch 14: Train err: 0.5095986038394416, Train loss: 1.4010658396268183 |Validation err: 0.448559670781893, Validation loss: 1.259381850560506\n",
      "Epoch 15: Train err: 0.5017452006980803, Train loss: 1.3804437968535366 |Validation err: 0.43621399176954734, Validation loss: 1.2288421416969457\n",
      "Epoch 16: Train err: 0.49476439790575916, Train loss: 1.3600575751243045 |Validation err: 0.43621399176954734, Validation loss: 1.2105331018628407\n",
      "Epoch 17: Train err: 0.49214659685863876, Train loss: 1.3422844559734404 |Validation err: 0.43209876543209874, Validation loss: 1.1956644730312833\n",
      "Epoch 18: Train err: 0.4816753926701571, Train loss: 1.3256158453215687 |Validation err: 0.42386831275720166, Validation loss: 1.1824027589319175\n",
      "Epoch 19: Train err: 0.4816753926701571, Train loss: 1.3120069085615467 |Validation err: 0.4279835390946502, Validation loss: 1.1674068381266338\n",
      "Epoch 20: Train err: 0.47731239092495636, Train loss: 1.2978402485398097 |Validation err: 0.42386831275720166, Validation loss: 1.161567503532755\n",
      "Finished Training\n",
      "Total time elapsed: 3158.86 seconds\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "trainm(net, batch_size=1, learning_rate=0.0001, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (d) [2 pt]\n",
    "Report the test accuracy of your best model. How does the test accuracy compare to part 4(d)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model):\n",
    "    data = testset\n",
    "    total = 0\n",
    "    correct =0\n",
    "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=32):\n",
    "        features = myfeature_model(imgs)\n",
    "        output = net(features) # We don't need to run F.softmax\n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(net)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The test accuracy increased from 62% to 67%. The network test accuracy improved noticebly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
